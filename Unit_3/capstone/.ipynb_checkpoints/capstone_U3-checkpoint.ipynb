{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 3 Supervised Learning Capstone\n",
    "\n",
    "This capstone project is fosused on prediction of the precense of heart disease in individuals using data obtained from traditional diagnostic tests. The data is provided by the Cleveland Clinic Database. The data was provided by [Kaggel](https://www.kaggle.com/) the HEART DISEASE webpage is at this link  [HD_Dataset](https://www.kaggle.com/ronitf/heart-disease-uci).\n",
    "\n",
    "#### Data Overview\n",
    "The original data set contained personal information and more features than is provide to the public. There were originally 76 attributes measured in the original data. The data has been scrubbed of personal identifiers and the attributes reduced to 14. Of the 14 attributes there are both catigorical and continous varibles. The target feature is binary to indicate either the precence or abcense of heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "from mlflow import sklearn as mlflow_sklearn\n",
    "\n",
    "import sklearn.datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import catboost\n",
    "import lightgbm \n",
    "import xgboost\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import six\n",
    "from collections import defaultdict\n",
    "from scipy import sparse, stats\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion, _fit_transform_one, _transform_one\n",
    "\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "### Data Set Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      "age         303 non-null int64\n",
      "sex         303 non-null int64\n",
      "cp          303 non-null int64\n",
      "trestbps    303 non-null int64\n",
      "chol        303 non-null int64\n",
      "fbs         303 non-null int64\n",
      "restecg     303 non-null int64\n",
      "thalach     303 non-null int64\n",
      "exang       303 non-null int64\n",
      "oldpeak     303 non-null float64\n",
      "slope       303 non-null int64\n",
      "ca          303 non-null int64\n",
      "thal        303 non-null int64\n",
      "target      303 non-null int64\n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.2 KB\n"
     ]
    }
   ],
   "source": [
    "# Read in data and look at the varibleas and thier data type\n",
    "df = pd.read_csv('heart.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample first three rows of the data set\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General stats on data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for missing data in the file \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable descriptions and explanations\n",
    "\n",
    "  1. age - subject's age in years\n",
    "\n",
    "  2. sex - subject's gender (1 = Male, 0 = female)\n",
    "\n",
    "  3. cp - chest pain type 4 values, (0 = typical angina, 1 = atypical angina, 2 = non-anginal pain, 3 = asymptomatic)\n",
    "\n",
    "      * Typical angina is a common condition caused from ischemia or the lack of blood or oxygen to the heart muscle, most common in men. The symptoms are reported as tightness or pain felt in the chest after physical activities or stress.\n",
    "\n",
    "      * Atypical angina is more common in women and is a more subtle with reported symptoms of fatigue, sleep disturbances, shortness of breath and may be accompanied with chest discomfort.\n",
    "\n",
    "      * Non-anginal pain is caused by other conditions and can easily be mistaken for angina in emergency situations where the patient’s well-being can take precedence over time consuming evaluations.\n",
    "\n",
    "      * Asymptomatic chest pain is the lack of the patient felling pain or tightness in their chest, yet other tests indicate there is the presence of myocardial infarction, \"the silent heart attack\"\n",
    "\n",
    "  4. trestbps - resting blood pressure in mm Hg, measured on admission to the hospital \n",
    "\n",
    "  5. chol - serum cholesterol measured in mg/dl \n",
    "\n",
    "  6. fbs - fasting blood sugar > 120 mg/dl, (1 = True, 0 = False)\n",
    "\n",
    "  7. restecg - resting electrocardiographic results (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite LVH (left ventricular hypertrophy) by Estes' criteria)\n",
    "\n",
    "      * Normal ecg and chest pain are typical symptoms of anxiety (panic attack).\n",
    "\n",
    "      * ST-T wave abnormality is commonly linked to myocardial (Heart Muscle) disease.\n",
    "\n",
    "      * LVH by Estes' criteria is an indication that the patient suffers from heart valve disease and may or may not have myocardial disease.\n",
    "\n",
    "  8. thalach - maximum heart rate achieved during an exercise protocol, measured in bpm (beats per minute)\n",
    "\n",
    "  9. exang - exercise induced angina (1 = True, 0 = False)\n",
    "\n",
    "  10. oldpeak - ST depression induced by exercise relative to rest, measured in mm\n",
    "\n",
    "      * ECG (electrocardiogram) originally was recorded on a paper chart where one square = to 1mm.\n",
    "\n",
    "      * ST segment depression may occur as a normal variant\n",
    "\n",
    "      * ST segment depression is a diagnostic tool to determine the presence of obstructive coronary atherosclerosis.\n",
    "\n",
    "  11. slope - the slope of the peak exercise ST segment (0 = upsloping, 1 = flat, 2 = down sloping)\n",
    "\n",
    "      * normal slope is upwards\n",
    "\n",
    "      * abnormal slope is flat or downward\n",
    "\n",
    "      * false positives are common in women\n",
    "\n",
    "  12. ca - number of major vessels (0-3) colored by fluoroscopy during an angiogram. Values of 0 to 4 indicating the number of vessels seen with blood flow going through them.\n",
    "\n",
    "      * Values of **zero** would question if the procedure was performed as no flow through the arteries is not realistic.\n",
    "\n",
    "      * An angiogram is an invasive procedure where a contrast dye in introduced by a catheter so the coronary arteries can be imaged using x-rays.\n",
    "\n",
    "      * The procedure is diagnostic and a surgery aid to place stents, perform angioplasty and for cardiac catheterization.\n",
    "\n",
    "      * Normal is where all 4 major coronary vessels can be seen\n",
    "\n",
    "  13. thal - Thallium stress test, where the contrast agent thallium is introduced to provide imaging by a gamma camera in order to image the perfusion of blood and oxygen throughout the heart muscle.  \n",
    "\n",
    "      * Original dataset values given (3 = normal; 6 = fixed defect; 7 = reversible defect) do not match the data set values 0-3.\n",
    "\n",
    "      * Assuming that a value of zero would mean the procedure was not performed, we will assign 1-3 with the assumption that 1 = normal, 2 = fixed defect, 3 = reversible defect.\n",
    "\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target bias\n",
    "print('Target Bias')\n",
    "target_sum = df['target'].count()\n",
    "target_count = df['target'].value_counts()\n",
    "percent_pos = round(target_count[0] / target_sum *100,1)\n",
    "percent_neg = 100 - percent_pos\n",
    "print('Total number targets is {}, individuals with heart disease present is {}% positve and {}% negitive'.\n",
    "      format(target_sum,str(percent_pos), str(percent_neg) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender bias\n",
    "print('Gender Bias')\n",
    "gender_sum = df['sex'].count()\n",
    "gender_count = df['sex'].value_counts()\n",
    "percent_male = round(gender_count[1] / gender_sum *100,1)\n",
    "percent_female = round(100 - percent_male,1)\n",
    "print('Of the {} participents, {}% are Male and {}% are Female'.\n",
    "      format(gender_sum,str(percent_male), str(percent_female) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine data for type, shape\n",
    "df.hist(bins=25, grid=False, figsize=(12,10), color='#86bf91', zorder=2, rwidth=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data sets based on Varible\n",
    "gender_data = df.copy(deep=True)\n",
    "gender_data.rename(columns={'sex':'Gender'}, inplace=True)\n",
    "\n",
    "gender_data['Gender'][gender_data['Gender'] == 0] = 'Female'\n",
    "gender_data['Gender'][gender_data['Gender'] == 1] = 'Male'\n",
    "\n",
    "gender_data['target'][gender_data['target'] == 0] = 'Healthy Heart'\n",
    "gender_data['target'][gender_data['target'] == 1] = 'Heart Disease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"oldpeak\"][df['target'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.set(style=\"whitegrid\", palette=\"pastel\", color_codes=True)\n",
    "ax = sns.violinplot(x=\"target\", y=\"age\", hue=\"Gender\",\n",
    "               split=True, inner=\"quart\",\n",
    "               palette={\"Male\": \"b\", \"Female\": \"y\"},\n",
    "               data=gender_data)\n",
    "ax.set_title('Heart Disease Gender Bias')\n",
    "ax.set_ylabel('Age [years]')\n",
    "ax.set_xlabel('Heart Condition')\n",
    "sns.despine(left=True)\n",
    "\n",
    "ax = sns.jointplot(df[\"oldpeak\"][df['target'] == 0], df[\"trestbps\"][df['target'] == 0], kind='kde')\n",
    "ax = ax.annotate(stats.pearsonr)\n",
    "\n",
    "ax = sns.jointplot(df[\"oldpeak\"][df['target'] == 1], df[\"trestbps\"][df['target'] == 1], kind='kde')\n",
    "ax = ax.annotate(stats.pearsonr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = sns.jointplot(\"chol\", \"age\", data=gender_data, kind='kde')\n",
    "ax = ax.annotate(stats.pearsonr)\n",
    "ax = ax.set_axis_labels('Cholestoral [mg/dl]', 'Age [years]')\n",
    "plt.title('Age vs Cholestoral', fontweight='bold')\n",
    "\n",
    "ax = sns.jointplot(\"trestbps\", \"age\", data=gender_data, kind='kde')\n",
    "ax = ax.annotate(stats.pearsonr)\n",
    "ax = ax.set_axis_labels('Resting Blood Pressure [mm Hg]', 'Age [years]')\n",
    "plt.title('Age vs Resting BP', fontweight='bold')\n",
    "\n",
    "ax = sns.jointplot(\"thalach\", \"age\", data=gender_data, kind='kde')\n",
    "ax = ax.annotate(stats.pearsonr)\n",
    "ax = ax.set_axis_labels('Maximum Heart Rate [bpm]', 'Age [years]')\n",
    "plt.title('Age vs Maximum HR', fontweight='bold')\n",
    "\n",
    "ax = sns.jointplot(\"oldpeak\", \"age\", data=gender_data, kind='kde')\n",
    "ax = ax.annotate(stats.pearsonr)\n",
    "ax = ax.set_axis_labels('ECG - ST Depression (exercise relative to rest) [mm]', 'Age [years]')\n",
    "plt.title('Age vs ST Depression', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(1, figsize=(18,16))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"pastel\", color_codes=True)\n",
    "plt.subplot(221)\n",
    "ax = sns.violinplot(x=\"target\", y=\"chol\", hue=\"Gender\",\n",
    "               split=True, inner=\"quart\",\n",
    "               palette={\"Male\": \"b\", \"Female\": \"y\"},\n",
    "               data=gender_data)\n",
    "ax.set_title('Cholesterol Bias', fontweight='bold')\n",
    "ax.set_ylabel('Cholestoral [mg/dl]')\n",
    "ax.set_xlabel('Heart Condition')\n",
    "sns.despine(left=True)\n",
    "\n",
    "# plt.figure(1, figsize=(8,5))\n",
    "#sns.set(style=\"whitegrid\", palette=\"pastel\", color_codes=True)\n",
    "plt.subplot(222)\n",
    "ax = sns.violinplot(x=\"target\", y=\"trestbps\", hue=\"Gender\",\n",
    "               split=True, inner=\"quart\",\n",
    "               palette={\"Male\": \"b\", \"Female\": \"y\"},\n",
    "               data=gender_data)\n",
    "ax.set_title('Resting Blood Presure Bias', fontweight='bold')\n",
    "ax.set_ylabel('Blood Pressure [mm Hg]')\n",
    "ax.set_xlabel('Heart Condition')\n",
    "sns.despine(left=True)\n",
    "\n",
    "\n",
    "# plt.figure(2, figsize=(16,10))\n",
    "#sns.set(style=\"whitegrid\", palette=\"pastel\", color_codes=True)\n",
    "plt.subplot(223)\n",
    "ax = sns.violinplot(x=\"target\", y=\"thalach\", hue=\"Gender\",\n",
    "               split=True, inner=\"quart\",\n",
    "               palette={\"Male\": \"b\", \"Female\": \"y\"},\n",
    "               data=gender_data)\n",
    "ax.set_title('Maximum Heart Rate Bias', fontweight='bold')\n",
    "ax.set_ylabel('Heart Rate [bpm]')\n",
    "ax.set_xlabel('Heart Condition')\n",
    "sns.despine(left=True)\n",
    "\n",
    "#plt.figure(4, figsize=(16,10))\n",
    "#sns.set(style=\"whitegrid\", palette=\"pastel\", color_codes=True)\n",
    "plt.subplot(224)\n",
    "ax = sns.violinplot(x=\"target\", y=\"oldpeak\", hue=\"Gender\",\n",
    "               split=True, inner=\"quart\",\n",
    "               palette={\"Male\": \"b\", \"Female\": \"y\"},\n",
    "               data=gender_data)\n",
    "ax.set_title('ST Depression Bias (exercise relative to rest)', fontweight='bold' )\n",
    "ax.set_ylabel('ST Depression [mm]')\n",
    "ax.set_xlabel('Heart Condition')\n",
    "sns.despine(left=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reorder columns to group varibles by type [continous, catagorical, binary]\n",
    "cols = list(df.columns.values)\n",
    "new_index = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'cp',  'restecg', 'slope', 'ca', 'thal', 'exang', 'fbs', 'sex', 'target']\n",
    "df = df.reindex(columns=new_index)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_index = [ 'cp',  'restecg', 'slope', 'ca', 'thal']\n",
    "# df[category_index] = df[category_index].astype('category')\n",
    "\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "age_female = df.age[df['sex']==0]\n",
    "age_male = df.age[df['sex']==1]\n",
    "df_age = df.copy()\n",
    "df_age = df_age.groupby('sex')\n",
    "print(df_age['age'].describe())\n",
    "# Plot Data\n",
    "age_male.hist(bins=30)\n",
    "age_female.hist(bins=30)\n",
    "plt.title('Histogram of Age Distribution')\n",
    "plt.legend(['male','female'])\n",
    "plt.xlabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.trestbps,  df.age)\n",
    "plt.scatter(df.chol,  df.age)\n",
    "plt.scatter(df.thalach,  df.age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasFeatureUnion(FeatureUnion):\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self._validate_transformers()\n",
    "        result = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_fit_transform_one)(trans, X, y, weight,\n",
    "                                        **fit_params)\n",
    "            for name, trans, weight in self._iter())\n",
    "\n",
    "        if not result:\n",
    "            # All transformers are None\n",
    "            return np.zeros((X.shape[0], 0))\n",
    "        Xs, transformers = zip(*result)\n",
    "        self._update_transformer_list(transformers)\n",
    "        if any(sparse.issparse(f) for f in Xs):\n",
    "            Xs = sparse.hstack(Xs).tocsr()\n",
    "        else:\n",
    "            Xs = self.merge_dataframes_by_column(Xs)\n",
    "        return Xs\n",
    "\n",
    "    def merge_dataframes_by_column(self, Xs):\n",
    "        return pd.concat(Xs, axis=\"columns\", copy=False)\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xs = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_transform_one)(trans, X, None, weight)\n",
    "            for name, trans, weight in self._iter())\n",
    "        if not Xs:\n",
    "            # All transformers are None\n",
    "            return np.zeros((X.shape[0], 0))\n",
    "        if any(sparse.issparse(f) for f in Xs):\n",
    "            Xs = sparse.hstack(Xs).tocsr()\n",
    "        else:\n",
    "            Xs = self.merge_dataframes_by_column(Xs)\n",
    "        return Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _name_estimators(estimators):\n",
    "    \"\"\"Generate names for estimators.\"\"\"\n",
    "\n",
    "    names = [type(estimator).__name__.lower() for estimator in estimators]\n",
    "    namecount = defaultdict(int)\n",
    "    for est, name in zip(estimators, names):\n",
    "        namecount[name] += 1\n",
    "\n",
    "    for k, v in list(six.iteritems(namecount)):\n",
    "        if v == 1:\n",
    "            del namecount[k]\n",
    "\n",
    "    for i in reversed(range(len(estimators))):\n",
    "        name = names[i]\n",
    "        if name in namecount:\n",
    "            names[i] += \"-%d\" % namecount[name]\n",
    "            namecount[name] -= 1\n",
    "\n",
    "    return list(zip(names, estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pandas_union(*transformers, **kwargs):\n",
    "    n_jobs = kwargs.pop('n_jobs', None)\n",
    "    if kwargs:\n",
    "        raise TypeError('Unknown keyword arguments: \"{}\"'\n",
    "                        .format(list(kwargs.keys())[0]))\n",
    "    return PandasFeatureUnion(_name_estimators(transformers), n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinalEncoderPandas(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.transformers = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        for column in self.columns:\n",
    "            self.transformers[column] = ce.OrdinalEncoder(return_df=False, handle_unknown=\"impute\").fit(X[[column]])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.drop(list(set(X.columns) - set(self.columns)), axis=1)\n",
    "        for column in self.columns:\n",
    "            X[column] = self.transformers[column].transform(X[[column]])\n",
    "            X[column] = X[column].apply(lambda x: x if x else -1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncoderPandas(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.transformers = {}\n",
    "        self.feature_names = {}\n",
    "        self.feature_names_all = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for column in self.columns:\n",
    "            self.transformers[column] = OneHotEncoder(sparse=False, handle_unknown='ignore').fit(X[[column]])\n",
    "            features = [f\"{column}_{i}\" for i in self.transformers[column].get_feature_names()]\n",
    "            self.feature_names[column] = features\n",
    "            for feature in features:\n",
    "                self.feature_names_all.append(feature)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        ohe_df_list = []\n",
    "        for column in self.columns:\n",
    "            ohe_df = pd.DataFrame(self.transformers[column].transform(X[[column]]))\n",
    "            feature_names = [f\"{column}_{i}\" for i in self.transformers[column].get_feature_names()]\n",
    "            ohe_df.columns = self.feature_names[column]\n",
    "            ohe_df_list.append(ohe_df)\n",
    "        ohe_df_concat = pd.concat(ohe_df_list, axis=1)\n",
    "        return ohe_df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropColumn(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, columns, no_drops):\n",
    "        self.columns = columns\n",
    "        self.no_drops = no_drops\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        for column in self.columns:\n",
    "            if column in X.columns:\n",
    "                drop_together = False\n",
    "                if self.no_drops:\n",
    "                    for no_drop in self.no_drops:\n",
    "                        if column == no_drop and self.no_drops[no_drop] not in X.columns:\n",
    "                            drop_together = True\n",
    "                if not drop_together:\n",
    "                    X = X.drop(columns=column)\n",
    "            else:\n",
    "                print(f\"Drop Warning: Column {column} not in X\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChangeColumnType(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, types):\n",
    "        self.types = types\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        for column in self.types.keys():\n",
    "            if column in X.columns:\n",
    "                X[column] = X[column].astype(self.types[column])\n",
    "            else:\n",
    "                print(f\"Change Warning: Column {column} not in X\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "- XGBoost/Random Forest requires OHE of categorical variables unless categorial variable is ordinal\n",
    "- XGBoost/LightGBM/Catboost supports missing variables, but RandomForests do not (most models in sklearn does not support missing values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features 5 to 9 (4 feature in total) categorical type (non-binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = list(df_samples.columns[5:9])\n",
    "target = \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in categorical_features:\n",
    "#     df_samples[i] = abs(df_samples[i]).astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for Models that does not support categorical variables\n",
    "\n",
    "Need to use OHE, only when you know the data is not ordinal, otherwise you can use ordinal encoding\n",
    "\n",
    "XGBoost, RandomForest (CART can handle categorical, but RF does not have this implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ohe = make_pipeline(\n",
    "    make_pandas_union(\n",
    "        DropColumn(columns=categorical_features, no_drops=None),\n",
    "        make_pipeline(\n",
    "            ChangeColumnType(types={i: str for i in categorical_features}),\n",
    "            OneHotEncoderPandas(columns=categorical_features)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ohe.fit_transform(df_samples).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_columns = list(set(pipe_ohe.fit_transform(df_samples).columns) - set([target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for models that support categorical variables\n",
    "\n",
    "LightGBM, CatBoost can handle categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cat = make_pipeline(\n",
    "    make_pandas_union(\n",
    "        DropColumn(columns=categorical_features, no_drops=None),\n",
    "        OrdinalEncoderPandas(columns=categorical_features)\n",
    "    ),\n",
    "    ChangeColumnType(types={i: \"category\" for i in categorical_features}),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cat.fit_transform(df_samples).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Testing/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples_ohe = pipe_ohe.fit_transform(df_samples)\n",
    "train_ohe, test_ohe = train_test_split(df_samples_ohe, test_size=0.2, stratify=df_samples_ohe[target], random_state=0)\n",
    "train_ohe, valid_ohe = train_test_split(train_ohe, test_size=0.2, stratify=train_ohe[target], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples_cat = pipe_cat.fit_transform(df_samples)\n",
    "train_cat, test_cat = train_test_split(df_samples_cat, test_size=0.2, stratify=df_samples_cat[target], random_state=0)\n",
    "train_cat, valid_cat = train_test_split(train_cat, test_size=0.2, stratify=train_cat[target], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    max_features=None,\n",
    "    n_estimators=20,\n",
    "    max_depth=4,\n",
    "    random_state=0,\n",
    "    n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "# Use validation set to modify hyperparameters\n",
    "print(accuracy_score(valid_ohe[target], rf_classifier.predict(valid_ohe[ohe_columns])))\n",
    "# Use testing set to evaluate final performance\n",
    "print(accuracy_score(test_ohe[target], rf_classifier.predict(test_ohe[ohe_columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = xgboost.XGBClassifier(\n",
    "    max_depth=4,\n",
    "    learning_rate=0.008,\n",
    "    n_estimators=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "# Use validation set to modify hyperparameters\n",
    "print(accuracy_score(valid_ohe[target], xgb_classifier.predict(valid_ohe[ohe_columns])))\n",
    "# Use testing set to evaluate final performance\n",
    "print(accuracy_score(test_ohe[target], xgb_classifier.predict(test_ohe[ohe_columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_classifier = lightgbm.LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    categorical_features=\"auto\",\n",
    "    max_depth=4,\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "# Use validation set to modify hyperparameters\n",
    "print(accuracy_score(valid_ohe[target], lgb_classifier.predict(valid_ohe[ohe_columns])))\n",
    "# Use testing set to evaluate final performance\n",
    "print(accuracy_score(test_ohe[target], lgb_classifier.predict(test_ohe[ohe_columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_classifier = catboost.CatBoostClassifier(\n",
    "    max_depth=4,\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=200,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "# Use validation set to modify hyperparameters\n",
    "print(accuracy_score(valid_ohe[target], cat_classifier.predict(valid_ohe[ohe_columns])))\n",
    "# Use testing set to evaluate final performance\n",
    "print(accuracy_score(test_ohe[target], cat_classifier.predict(test_ohe[ohe_columns])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Training/Testing/Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Random Forest\"):\n",
    "    criterion = \"entropy\"\n",
    "    max_features = None\n",
    "    n_estimators = 20\n",
    "    max_depth = 4\n",
    "    \n",
    "    rf_classifier = RandomForestClassifier(\n",
    "        criterion=criterion,\n",
    "        max_features=max_features,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=0,\n",
    "        n_jobs=4)\n",
    "    rf_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "    \n",
    "    valid_accuracy = accuracy_score(valid_ohe[target], rf_classifier.predict(valid_ohe[ohe_columns]))\n",
    "    test_accuracy = accuracy_score(test_ohe[target], rf_classifier.predict(test_ohe[ohe_columns]))\n",
    "    \n",
    "    mlflow.log_param(\"criterion\", criterion)\n",
    "    mlflow.log_param(\"max_features\", max_features)\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    \n",
    "    mlflow.log_metric(\"valid_accuracy\", valid_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "    mlflow_sklearn.log_model(rf_classifier, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"XGBoost\"):\n",
    "    n_estimators = 200\n",
    "    max_depth = 4\n",
    "    learning_rate = 0.008\n",
    "    \n",
    "    xgb_classifier = xgboost.XGBClassifier(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators\n",
    "    )\n",
    "    xgb_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "    \n",
    "    valid_accuracy = accuracy_score(valid_ohe[target], xgb_classifier.predict(valid_ohe[ohe_columns]))\n",
    "    test_accuracy = accuracy_score(test_ohe[target], xgb_classifier.predict(test_ohe[ohe_columns]))\n",
    "    \n",
    "    mlflow.log_param(\"criterion\", criterion)\n",
    "    mlflow.log_param(\"max_features\", max_features)\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    \n",
    "    mlflow.log_metric(\"valid_accuracy\", valid_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "    mlflow_sklearn.log_model(xgb_classifier, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"LightGBM\"):\n",
    "    objective = \"binary\"\n",
    "    categorical_features = \"auto\"\n",
    "    n_estimators = 200\n",
    "    max_depth = 4\n",
    "    learning_rate = 0.01\n",
    "    \n",
    "    lgb_classifier = lightgbm.LGBMClassifier(\n",
    "        objective=objective,\n",
    "        categorical_features=categorical_features,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators\n",
    "    )\n",
    "    lgb_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "    \n",
    "    valid_accuracy = accuracy_score(valid_ohe[target], lgb_classifier.predict(valid_ohe[ohe_columns]))\n",
    "    test_accuracy = accuracy_score(test_ohe[target], lgb_classifier.predict(test_ohe[ohe_columns]))\n",
    "    \n",
    "    mlflow.log_param(\"criterion\", criterion)\n",
    "    mlflow.log_param(\"max_features\", max_features)\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    \n",
    "    mlflow.log_metric(\"valid_accuracy\", valid_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "    mlflow_sklearn.log_model(lgb_classifier, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"CatBoost\"):\n",
    "    n_estimators = 200\n",
    "    max_depth = 8\n",
    "    learning_rate = 0.01\n",
    "    \n",
    "    cat_classifier = catboost.CatBoostClassifier(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        verbose=0\n",
    "    )\n",
    "    cat_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "    \n",
    "    valid_accuracy = accuracy_score(valid_ohe[target], cat_classifier.predict(valid_ohe[ohe_columns]))\n",
    "    test_accuracy = accuracy_score(test_ohe[target], cat_classifier.predict(test_ohe[ohe_columns]))\n",
    "    \n",
    "    mlflow.log_param(\"criterion\", criterion)\n",
    "    mlflow.log_param(\"max_features\", max_features)\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    \n",
    "    mlflow.log_metric(\"valid_accuracy\", valid_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "    mlflow_sklearn.log_model(cat_classifier, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Testing/Validation with Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Testing with CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Testing with CV with Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested CV with Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
