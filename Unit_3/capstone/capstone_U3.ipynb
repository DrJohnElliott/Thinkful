{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "from mlflow import sklearn as mlflow_sklearn\n",
    "\n",
    "import sklearn.datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import catboost\n",
    "import lightgbm as lgb\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import six\n",
    "from collections import defaultdict\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion, _fit_transform_one, _transform_one\n",
    "\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "### Data Set Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
      "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
      "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   0     1       1  \n",
      "1   0     2       1  \n",
      "2   0     2       1  \n",
      "\n",
      "Data bias\n",
      "Total number targets is 303, with 45.5% positve and 54.5% negitive\n",
      "Of the 303 participents, 68.3% are Male and 31.7% are Female\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('heart.csv')\n",
    "print(df.head(3))\n",
    "print('')\n",
    "# Target bias\n",
    "print('Data bias')\n",
    "target_sum = df['target'].count()\n",
    "target_count = df['target'].value_counts()\n",
    "percent_pos = round(target_count[0] / target_sum *100,1)\n",
    "percent_neg = 100 - percent_pos\n",
    "print('Total number targets is {}, with {}% positve and {}% negitive'.\n",
    "      format(target_sum,str(percent_pos), str(percent_neg) ))\n",
    "\n",
    "# Gender bias\n",
    "gender_sum = df['sex'].count()\n",
    "gender_count = df['sex'].value_counts()\n",
    "percent_male = round(gender_count[1] / gender_sum *100,1)\n",
    "percent_female = round(100 - percent_male,1)\n",
    "print('Of the {} participents, {}% are Male and {}% are Female'.\n",
    "      format(gender_sum,str(percent_male), str(percent_female) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_data = df['age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasFeatureUnion(FeatureUnion):\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self._validate_transformers()\n",
    "        result = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_fit_transform_one)(trans, X, y, weight,\n",
    "                                        **fit_params)\n",
    "            for name, trans, weight in self._iter())\n",
    "\n",
    "        if not result:\n",
    "            # All transformers are None\n",
    "            return np.zeros((X.shape[0], 0))\n",
    "        Xs, transformers = zip(*result)\n",
    "        self._update_transformer_list(transformers)\n",
    "        if any(sparse.issparse(f) for f in Xs):\n",
    "            Xs = sparse.hstack(Xs).tocsr()\n",
    "        else:\n",
    "            Xs = self.merge_dataframes_by_column(Xs)\n",
    "        return Xs\n",
    "\n",
    "    def merge_dataframes_by_column(self, Xs):\n",
    "        return pd.concat(Xs, axis=\"columns\", copy=False)\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xs = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_transform_one)(trans, X, None, weight)\n",
    "            for name, trans, weight in self._iter())\n",
    "        if not Xs:\n",
    "            # All transformers are None\n",
    "            return np.zeros((X.shape[0], 0))\n",
    "        if any(sparse.issparse(f) for f in Xs):\n",
    "            Xs = sparse.hstack(Xs).tocsr()\n",
    "        else:\n",
    "            Xs = self.merge_dataframes_by_column(Xs)\n",
    "        return Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _name_estimators(estimators):\n",
    "    \"\"\"Generate names for estimators.\"\"\"\n",
    "\n",
    "    names = [type(estimator).__name__.lower() for estimator in estimators]\n",
    "    namecount = defaultdict(int)\n",
    "    for est, name in zip(estimators, names):\n",
    "        namecount[name] += 1\n",
    "\n",
    "    for k, v in list(six.iteritems(namecount)):\n",
    "        if v == 1:\n",
    "            del namecount[k]\n",
    "\n",
    "    for i in reversed(range(len(estimators))):\n",
    "        name = names[i]\n",
    "        if name in namecount:\n",
    "            names[i] += \"-%d\" % namecount[name]\n",
    "            namecount[name] -= 1\n",
    "\n",
    "    return list(zip(names, estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pandas_union(*transformers, **kwargs):\n",
    "    n_jobs = kwargs.pop('n_jobs', None)\n",
    "    if kwargs:\n",
    "        raise TypeError('Unknown keyword arguments: \"{}\"'\n",
    "                        .format(list(kwargs.keys())[0]))\n",
    "    return PandasFeatureUnion(_name_estimators(transformers), n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinalEncoderPandas(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.transformers = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        for column in self.columns:\n",
    "            self.transformers[column] = ce.OrdinalEncoder(return_df=False, handle_unknown=\"impute\").fit(X[[column]])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.drop(list(set(X.columns) - set(self.columns)), axis=1)\n",
    "        for column in self.columns:\n",
    "            X[column] = self.transformers[column].transform(X[[column]])\n",
    "            X[column] = X[column].apply(lambda x: x if x else -1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncoderPandas(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.transformers = {}\n",
    "        self.feature_names = {}\n",
    "        self.feature_names_all = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for column in self.columns:\n",
    "            self.transformers[column] = OneHotEncoder(sparse=False, handle_unknown='ignore').fit(X[[column]])\n",
    "            features = [f\"{column}_{i}\" for i in self.transformers[column].get_feature_names()]\n",
    "            self.feature_names[column] = features\n",
    "            for feature in features:\n",
    "                self.feature_names_all.append(feature)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        ohe_df_list = []\n",
    "        for column in self.columns:\n",
    "            ohe_df = pd.DataFrame(self.transformers[column].transform(X[[column]]))\n",
    "            feature_names = [f\"{column}_{i}\" for i in self.transformers[column].get_feature_names()]\n",
    "            ohe_df.columns = self.feature_names[column]\n",
    "            ohe_df_list.append(ohe_df)\n",
    "        ohe_df_concat = pd.concat(ohe_df_list, axis=1)\n",
    "        return ohe_df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropColumn(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, columns, no_drops):\n",
    "        self.columns = columns\n",
    "        self.no_drops = no_drops\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        for column in self.columns:\n",
    "            if column in X.columns:\n",
    "                drop_together = False\n",
    "                if self.no_drops:\n",
    "                    for no_drop in self.no_drops:\n",
    "                        if column == no_drop and self.no_drops[no_drop] not in X.columns:\n",
    "                            drop_together = True\n",
    "                if not drop_together:\n",
    "                    X = X.drop(columns=column)\n",
    "            else:\n",
    "                print(f\"Drop Warning: Column {column} not in X\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChangeColumnType(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, types):\n",
    "        self.types = types\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        for column in self.types.keys():\n",
    "            if column in X.columns:\n",
    "                X[column] = X[column].astype(self.types[column])\n",
    "            else:\n",
    "                print(f\"Change Warning: Column {column} not in X\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "- XGBoost/Random Forest requires OHE of categorical variables unless categorial variable is ordinal\n",
    "- XGBoost/LightGBM/Catboost supports missing variables, but RandomForests do not (most models in sklearn does not support missing values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic dataset with features 0 to 3 (4 feature in total) categorical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sklearn.datasets.make_classification(n_samples=100000, scale=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [f\"feature_{i}\" for i in range(samples[0].shape[1])]\n",
    "target = \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples = pd.concat([pd.DataFrame(samples[0], columns=feature_names), pd.DataFrame(samples[1], columns=[target])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = list(df_samples.columns[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categorical_features:\n",
    "    df_samples[i] = abs(df_samples[i]).astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.645832</td>\n",
       "      <td>-23.556619</td>\n",
       "      <td>14.920084</td>\n",
       "      <td>-4.116929</td>\n",
       "      <td>-9.131104</td>\n",
       "      <td>2.125107</td>\n",
       "      <td>...</td>\n",
       "      <td>2.361506</td>\n",
       "      <td>-0.189242</td>\n",
       "      <td>5.739019</td>\n",
       "      <td>-2.016198</td>\n",
       "      <td>16.778215</td>\n",
       "      <td>9.035596</td>\n",
       "      <td>-7.726635</td>\n",
       "      <td>-3.518649</td>\n",
       "      <td>16.847575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.972505</td>\n",
       "      <td>6.832732</td>\n",
       "      <td>-8.335915</td>\n",
       "      <td>8.297369</td>\n",
       "      <td>7.750135</td>\n",
       "      <td>18.976983</td>\n",
       "      <td>...</td>\n",
       "      <td>23.377719</td>\n",
       "      <td>-18.228802</td>\n",
       "      <td>-2.224554</td>\n",
       "      <td>-0.251290</td>\n",
       "      <td>-7.388667</td>\n",
       "      <td>0.141325</td>\n",
       "      <td>-4.956575</td>\n",
       "      <td>1.528967</td>\n",
       "      <td>10.877658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.891787</td>\n",
       "      <td>-4.344791</td>\n",
       "      <td>2.434333</td>\n",
       "      <td>-15.868354</td>\n",
       "      <td>7.169750</td>\n",
       "      <td>1.856554</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.959649</td>\n",
       "      <td>-0.403657</td>\n",
       "      <td>3.378730</td>\n",
       "      <td>4.083821</td>\n",
       "      <td>-10.070729</td>\n",
       "      <td>1.227475</td>\n",
       "      <td>-14.536854</td>\n",
       "      <td>-4.519916</td>\n",
       "      <td>-3.603694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>-4.322641</td>\n",
       "      <td>-7.138765</td>\n",
       "      <td>2.785310</td>\n",
       "      <td>7.352866</td>\n",
       "      <td>-23.127705</td>\n",
       "      <td>3.468762</td>\n",
       "      <td>...</td>\n",
       "      <td>7.242841</td>\n",
       "      <td>14.721356</td>\n",
       "      <td>-5.952227</td>\n",
       "      <td>-4.674254</td>\n",
       "      <td>-2.795130</td>\n",
       "      <td>-4.940003</td>\n",
       "      <td>12.700518</td>\n",
       "      <td>-5.517182</td>\n",
       "      <td>-2.996830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3.140241</td>\n",
       "      <td>11.670064</td>\n",
       "      <td>11.100301</td>\n",
       "      <td>2.774834</td>\n",
       "      <td>0.150274</td>\n",
       "      <td>-11.490540</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.888000</td>\n",
       "      <td>-3.621434</td>\n",
       "      <td>4.478216</td>\n",
       "      <td>3.600383</td>\n",
       "      <td>-11.334051</td>\n",
       "      <td>-2.805697</td>\n",
       "      <td>14.555254</td>\n",
       "      <td>-2.763186</td>\n",
       "      <td>3.916138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature_0 feature_1 feature_2 feature_3  feature_4  feature_5  feature_6  \\\n",
       "0        12         4        10         2   0.645832 -23.556619  14.920084   \n",
       "1         8         4         5         8  -0.972505   6.832732  -8.335915   \n",
       "2         4         2         1         2  20.891787  -4.344791   2.434333   \n",
       "3        20         3         1        16  -4.322641  -7.138765   2.785310   \n",
       "4         8         5         1         7   3.140241  11.670064  11.100301   \n",
       "\n",
       "   feature_7  feature_8  feature_9  ...  feature_11  feature_12  feature_13  \\\n",
       "0  -4.116929  -9.131104   2.125107  ...    2.361506   -0.189242    5.739019   \n",
       "1   8.297369   7.750135  18.976983  ...   23.377719  -18.228802   -2.224554   \n",
       "2 -15.868354   7.169750   1.856554  ...   -8.959649   -0.403657    3.378730   \n",
       "3   7.352866 -23.127705   3.468762  ...    7.242841   14.721356   -5.952227   \n",
       "4   2.774834   0.150274 -11.490540  ...   -4.888000   -3.621434    4.478216   \n",
       "\n",
       "   feature_14  feature_15  feature_16  feature_17  feature_18  feature_19  \\\n",
       "0   -2.016198   16.778215    9.035596   -7.726635   -3.518649   16.847575   \n",
       "1   -0.251290   -7.388667    0.141325   -4.956575    1.528967   10.877658   \n",
       "2    4.083821  -10.070729    1.227475  -14.536854   -4.519916   -3.603694   \n",
       "3   -4.674254   -2.795130   -4.940003   12.700518   -5.517182   -2.996830   \n",
       "4    3.600383  -11.334051   -2.805697   14.555254   -2.763186    3.916138   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    50050\n",
       "0    49950\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samples[target].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for Models that does not support categorical variables\n",
    "\n",
    "Need to use OHE, only when you know the data is not ordinal, otherwise you can use ordinal encoding\n",
    "\n",
    "XGBoost, RandomForest (CART can handle categorical, but RF does not have this implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ohe = make_pipeline(\n",
    "    make_pandas_union(\n",
    "        DropColumn(columns=categorical_features, no_drops=None),\n",
    "        make_pipeline(\n",
    "            ChangeColumnType(types={i: str for i in categorical_features}),\n",
    "            OneHotEncoderPandas(columns=categorical_features)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_3_x0_40</th>\n",
       "      <th>feature_3_x0_41</th>\n",
       "      <th>feature_3_x0_42</th>\n",
       "      <th>feature_3_x0_43</th>\n",
       "      <th>feature_3_x0_44</th>\n",
       "      <th>feature_3_x0_5</th>\n",
       "      <th>feature_3_x0_6</th>\n",
       "      <th>feature_3_x0_7</th>\n",
       "      <th>feature_3_x0_8</th>\n",
       "      <th>feature_3_x0_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.645832</td>\n",
       "      <td>-23.556619</td>\n",
       "      <td>14.920084</td>\n",
       "      <td>-4.116929</td>\n",
       "      <td>-9.131104</td>\n",
       "      <td>2.125107</td>\n",
       "      <td>-5.604669</td>\n",
       "      <td>2.361506</td>\n",
       "      <td>-0.189242</td>\n",
       "      <td>5.739019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.972505</td>\n",
       "      <td>6.832732</td>\n",
       "      <td>-8.335915</td>\n",
       "      <td>8.297369</td>\n",
       "      <td>7.750135</td>\n",
       "      <td>18.976983</td>\n",
       "      <td>-0.398073</td>\n",
       "      <td>23.377719</td>\n",
       "      <td>-18.228802</td>\n",
       "      <td>-2.224554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.891787</td>\n",
       "      <td>-4.344791</td>\n",
       "      <td>2.434333</td>\n",
       "      <td>-15.868354</td>\n",
       "      <td>7.169750</td>\n",
       "      <td>1.856554</td>\n",
       "      <td>13.228155</td>\n",
       "      <td>-8.959649</td>\n",
       "      <td>-0.403657</td>\n",
       "      <td>3.378730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.322641</td>\n",
       "      <td>-7.138765</td>\n",
       "      <td>2.785310</td>\n",
       "      <td>7.352866</td>\n",
       "      <td>-23.127705</td>\n",
       "      <td>3.468762</td>\n",
       "      <td>-10.794777</td>\n",
       "      <td>7.242841</td>\n",
       "      <td>14.721356</td>\n",
       "      <td>-5.952227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.140241</td>\n",
       "      <td>11.670064</td>\n",
       "      <td>11.100301</td>\n",
       "      <td>2.774834</td>\n",
       "      <td>0.150274</td>\n",
       "      <td>-11.490540</td>\n",
       "      <td>6.220968</td>\n",
       "      <td>-4.888000</td>\n",
       "      <td>-3.621434</td>\n",
       "      <td>4.478216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_4  feature_5  feature_6  feature_7  feature_8  feature_9  \\\n",
       "0   0.645832 -23.556619  14.920084  -4.116929  -9.131104   2.125107   \n",
       "1  -0.972505   6.832732  -8.335915   8.297369   7.750135  18.976983   \n",
       "2  20.891787  -4.344791   2.434333 -15.868354   7.169750   1.856554   \n",
       "3  -4.322641  -7.138765   2.785310   7.352866 -23.127705   3.468762   \n",
       "4   3.140241  11.670064  11.100301   2.774834   0.150274 -11.490540   \n",
       "\n",
       "   feature_10  feature_11  feature_12  feature_13  ...  feature_3_x0_40  \\\n",
       "0   -5.604669    2.361506   -0.189242    5.739019  ...              0.0   \n",
       "1   -0.398073   23.377719  -18.228802   -2.224554  ...              0.0   \n",
       "2   13.228155   -8.959649   -0.403657    3.378730  ...              0.0   \n",
       "3  -10.794777    7.242841   14.721356   -5.952227  ...              0.0   \n",
       "4    6.220968   -4.888000   -3.621434    4.478216  ...              0.0   \n",
       "\n",
       "   feature_3_x0_41  feature_3_x0_42  feature_3_x0_43  feature_3_x0_44  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   feature_3_x0_5  feature_3_x0_6  feature_3_x0_7  feature_3_x0_8  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             1.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             1.0             0.0   \n",
       "\n",
       "   feature_3_x0_9  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_ohe.fit_transform(df_samples).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_columns = list(set(pipe_ohe.fit_transform(df_samples).columns) - set([target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for models that support categorical variables\n",
    "\n",
    "LightGBM, CatBoost can handle categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cat = make_pipeline(\n",
    "    make_pandas_union(\n",
    "        DropColumn(columns=categorical_features, no_drops=None),\n",
    "        OrdinalEncoderPandas(columns=categorical_features)\n",
    "    ),\n",
    "    ChangeColumnType(types={i: \"category\" for i in categorical_features}),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>target</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.645832</td>\n",
       "      <td>-23.556619</td>\n",
       "      <td>14.920084</td>\n",
       "      <td>-4.116929</td>\n",
       "      <td>-9.131104</td>\n",
       "      <td>2.125107</td>\n",
       "      <td>-5.604669</td>\n",
       "      <td>2.361506</td>\n",
       "      <td>-0.189242</td>\n",
       "      <td>5.739019</td>\n",
       "      <td>...</td>\n",
       "      <td>16.778215</td>\n",
       "      <td>9.035596</td>\n",
       "      <td>-7.726635</td>\n",
       "      <td>-3.518649</td>\n",
       "      <td>16.847575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.972505</td>\n",
       "      <td>6.832732</td>\n",
       "      <td>-8.335915</td>\n",
       "      <td>8.297369</td>\n",
       "      <td>7.750135</td>\n",
       "      <td>18.976983</td>\n",
       "      <td>-0.398073</td>\n",
       "      <td>23.377719</td>\n",
       "      <td>-18.228802</td>\n",
       "      <td>-2.224554</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.388667</td>\n",
       "      <td>0.141325</td>\n",
       "      <td>-4.956575</td>\n",
       "      <td>1.528967</td>\n",
       "      <td>10.877658</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.891787</td>\n",
       "      <td>-4.344791</td>\n",
       "      <td>2.434333</td>\n",
       "      <td>-15.868354</td>\n",
       "      <td>7.169750</td>\n",
       "      <td>1.856554</td>\n",
       "      <td>13.228155</td>\n",
       "      <td>-8.959649</td>\n",
       "      <td>-0.403657</td>\n",
       "      <td>3.378730</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.070729</td>\n",
       "      <td>1.227475</td>\n",
       "      <td>-14.536854</td>\n",
       "      <td>-4.519916</td>\n",
       "      <td>-3.603694</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.322641</td>\n",
       "      <td>-7.138765</td>\n",
       "      <td>2.785310</td>\n",
       "      <td>7.352866</td>\n",
       "      <td>-23.127705</td>\n",
       "      <td>3.468762</td>\n",
       "      <td>-10.794777</td>\n",
       "      <td>7.242841</td>\n",
       "      <td>14.721356</td>\n",
       "      <td>-5.952227</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.795130</td>\n",
       "      <td>-4.940003</td>\n",
       "      <td>12.700518</td>\n",
       "      <td>-5.517182</td>\n",
       "      <td>-2.996830</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.140241</td>\n",
       "      <td>11.670064</td>\n",
       "      <td>11.100301</td>\n",
       "      <td>2.774834</td>\n",
       "      <td>0.150274</td>\n",
       "      <td>-11.490540</td>\n",
       "      <td>6.220968</td>\n",
       "      <td>-4.888000</td>\n",
       "      <td>-3.621434</td>\n",
       "      <td>4.478216</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.334051</td>\n",
       "      <td>-2.805697</td>\n",
       "      <td>14.555254</td>\n",
       "      <td>-2.763186</td>\n",
       "      <td>3.916138</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_4  feature_5  feature_6  feature_7  feature_8  feature_9  \\\n",
       "0   0.645832 -23.556619  14.920084  -4.116929  -9.131104   2.125107   \n",
       "1  -0.972505   6.832732  -8.335915   8.297369   7.750135  18.976983   \n",
       "2  20.891787  -4.344791   2.434333 -15.868354   7.169750   1.856554   \n",
       "3  -4.322641  -7.138765   2.785310   7.352866 -23.127705   3.468762   \n",
       "4   3.140241  11.670064  11.100301   2.774834   0.150274 -11.490540   \n",
       "\n",
       "   feature_10  feature_11  feature_12  feature_13  ...  feature_15  \\\n",
       "0   -5.604669    2.361506   -0.189242    5.739019  ...   16.778215   \n",
       "1   -0.398073   23.377719  -18.228802   -2.224554  ...   -7.388667   \n",
       "2   13.228155   -8.959649   -0.403657    3.378730  ...  -10.070729   \n",
       "3  -10.794777    7.242841   14.721356   -5.952227  ...   -2.795130   \n",
       "4    6.220968   -4.888000   -3.621434    4.478216  ...  -11.334051   \n",
       "\n",
       "   feature_16  feature_17  feature_18  feature_19  target  feature_0  \\\n",
       "0    9.035596   -7.726635   -3.518649   16.847575       0          1   \n",
       "1    0.141325   -4.956575    1.528967   10.877658       1          2   \n",
       "2    1.227475  -14.536854   -4.519916   -3.603694       1          3   \n",
       "3   -4.940003   12.700518   -5.517182   -2.996830       1          4   \n",
       "4   -2.805697   14.555254   -2.763186    3.916138       1          2   \n",
       "\n",
       "  feature_1 feature_2 feature_3  \n",
       "0         1         1         1  \n",
       "1         1         2         2  \n",
       "2         2         3         1  \n",
       "3         3         3         3  \n",
       "4         4         3         4  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cat.fit_transform(df_samples).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Testing/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples_ohe = pipe_ohe.fit_transform(df_samples)\n",
    "train_ohe, test_ohe = train_test_split(df_samples_ohe, test_size=0.2, stratify=df_samples_ohe[target], random_state=0)\n",
    "train_ohe, valid_ohe = train_test_split(train_ohe, test_size=0.2, stratify=train_ohe[target], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples_cat = pipe_cat.fit_transform(df_samples)\n",
    "train_cat, test_cat = train_test_split(df_samples_cat, test_size=0.2, stratify=df_samples_cat[target], random_state=0)\n",
    "train_cat, valid_cat = train_test_split(train_cat, test_size=0.2, stratify=train_cat[target], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    max_features=None,\n",
    "    n_estimators=20,\n",
    "    max_depth=4,\n",
    "    random_state=0,\n",
    "    n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.903625\n",
      "0.89655\n"
     ]
    }
   ],
   "source": [
    "rf_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "# Use validation set to modify hyperparameters\n",
    "print(accuracy_score(valid_ohe[target], rf_classifier.predict(valid_ohe[ohe_columns])))\n",
    "# Use testing set to evaluate final performance\n",
    "print(accuracy_score(test_ohe[target], rf_classifier.predict(test_ohe[ohe_columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = xgboost.XGBClassifier(\n",
    "    max_depth=4,\n",
    "    learning_rate=0.008,\n",
    "    n_estimators=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908625\n",
      "0.90415\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "# Use validation set to modify hyperparameters\n",
    "print(accuracy_score(valid_ohe[target], xgb_classifier.predict(valid_ohe[ohe_columns])))\n",
    "# Use testing set to evaluate final performance\n",
    "print(accuracy_score(test_ohe[target], xgb_classifier.predict(test_ohe[ohe_columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_classifier = lightgbm.LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    categorical_features=\"auto\",\n",
    "    max_depth=4,\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9096875\n",
      "0.90585\n"
     ]
    }
   ],
   "source": [
    "lgb_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "# Use validation set to modify hyperparameters\n",
    "print(accuracy_score(valid_ohe[target], lgb_classifier.predict(valid_ohe[ohe_columns])))\n",
    "# Use testing set to evaluate final performance\n",
    "print(accuracy_score(test_ohe[target], lgb_classifier.predict(test_ohe[ohe_columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_classifier = catboost.CatBoostClassifier(\n",
    "    max_depth=4,\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=200,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.902125\n",
      "0.90025\n"
     ]
    }
   ],
   "source": [
    "cat_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "# Use validation set to modify hyperparameters\n",
    "print(accuracy_score(valid_ohe[target], cat_classifier.predict(valid_ohe[ohe_columns])))\n",
    "# Use testing set to evaluate final performance\n",
    "print(accuracy_score(test_ohe[target], cat_classifier.predict(test_ohe[ohe_columns])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Training/Testing/Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Random Forest\"):\n",
    "    criterion = \"entropy\"\n",
    "    max_features = None\n",
    "    n_estimators = 20\n",
    "    max_depth = 4\n",
    "    \n",
    "    rf_classifier = RandomForestClassifier(\n",
    "        criterion=criterion,\n",
    "        max_features=max_features,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=0,\n",
    "        n_jobs=4)\n",
    "    rf_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "    \n",
    "    valid_accuracy = accuracy_score(valid_ohe[target], rf_classifier.predict(valid_ohe[ohe_columns]))\n",
    "    test_accuracy = accuracy_score(test_ohe[target], rf_classifier.predict(test_ohe[ohe_columns]))\n",
    "    \n",
    "    mlflow.log_param(\"criterion\", criterion)\n",
    "    mlflow.log_param(\"max_features\", max_features)\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    \n",
    "    mlflow.log_metric(\"valid_accuracy\", valid_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "    mlflow_sklearn.log_model(rf_classifier, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"XGBoost\"):\n",
    "    n_estimators = 200\n",
    "    max_depth = 4\n",
    "    learning_rate = 0.008\n",
    "    \n",
    "    xgb_classifier = xgboost.XGBClassifier(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators\n",
    "    )\n",
    "    xgb_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "    \n",
    "    valid_accuracy = accuracy_score(valid_ohe[target], xgb_classifier.predict(valid_ohe[ohe_columns]))\n",
    "    test_accuracy = accuracy_score(test_ohe[target], xgb_classifier.predict(test_ohe[ohe_columns]))\n",
    "    \n",
    "    mlflow.log_param(\"criterion\", criterion)\n",
    "    mlflow.log_param(\"max_features\", max_features)\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    \n",
    "    mlflow.log_metric(\"valid_accuracy\", valid_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "    mlflow_sklearn.log_model(xgb_classifier, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"LightGBM\"):\n",
    "    objective = \"binary\"\n",
    "    categorical_features = \"auto\"\n",
    "    n_estimators = 200\n",
    "    max_depth = 4\n",
    "    learning_rate = 0.01\n",
    "    \n",
    "    lgb_classifier = lightgbm.LGBMClassifier(\n",
    "        objective=objective,\n",
    "        categorical_features=categorical_features,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators\n",
    "    )\n",
    "    lgb_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "    \n",
    "    valid_accuracy = accuracy_score(valid_ohe[target], lgb_classifier.predict(valid_ohe[ohe_columns]))\n",
    "    test_accuracy = accuracy_score(test_ohe[target], lgb_classifier.predict(test_ohe[ohe_columns]))\n",
    "    \n",
    "    mlflow.log_param(\"criterion\", criterion)\n",
    "    mlflow.log_param(\"max_features\", max_features)\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    \n",
    "    mlflow.log_metric(\"valid_accuracy\", valid_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "    mlflow_sklearn.log_model(lgb_classifier, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"CatBoost\"):\n",
    "    n_estimators = 200\n",
    "    max_depth = 4\n",
    "    learning_rate = 0.01\n",
    "    \n",
    "    cat_classifier = catboost.CatBoostClassifier(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        verbose=0\n",
    "    )\n",
    "    cat_classifier.fit(X=train_ohe[ohe_columns], y=train_ohe[target])\n",
    "    \n",
    "    valid_accuracy = accuracy_score(valid_ohe[target], cat_classifier.predict(valid_ohe[ohe_columns]))\n",
    "    test_accuracy = accuracy_score(test_ohe[target], cat_classifier.predict(test_ohe[ohe_columns]))\n",
    "    \n",
    "    mlflow.log_param(\"criterion\", criterion)\n",
    "    mlflow.log_param(\"max_features\", max_features)\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    \n",
    "    mlflow.log_metric(\"valid_accuracy\", valid_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "    mlflow_sklearn.log_model(cat_classifier, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-03-28 20:06:01 -0600] [4664] [INFO] Starting gunicorn 19.9.0\n",
      "[2019-03-28 20:06:01 -0600] [4664] [INFO] Listening at: http://0.0.0.0:5000 (4664)\n",
      "[2019-03-28 20:06:01 -0600] [4664] [INFO] Using worker: sync\n",
      "[2019-03-28 20:06:01 -0600] [4667] [INFO] Booting worker with pid: 4667\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Testing/Validation with Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Testing with CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Testing with CV with Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested CV with Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ML-Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
